# Non-stationary Time series
# @ Michael

# In this R script, I will go through the non-stationary time series properties

# Trend Vs. Difference-stationary Series
# assume y_t = D_t + z_t (deterministic trend and stochastic component)

# if all roots of the AR polynomial lie outside the unit circle
# it is stationary around a deterministic trend I(0)

# one root lie on the circle - difference stationary (unit root) I(1)

# y_t = y_{t-1} + \mu = y_0 + \mu t
# y_t = y_{t-1} + \varepsilon_t = y_0 + sum_{s=1}^t \varepsilon_s

# The key point is: where does the time get into the model !!
# For economic growth, I think the difference-stationary model is more
# plausible as the technology is more like randomly get into the economy

# Or, maybe the both? Let's keep exploring

# Firstly, we will review the stationary process AR, MA, ARMA process

###############################################################################
# AR(1)
###############################################################################

# Simulation of AR(1)-process with $\theta = 0.9$
set.seed(15689)
y <- arima.sim(n = 100, list(ar = 0.9), innov = rnorm(100))
pdf('./Figures/Ar1Sim.pdf', width=9, height=8)
par(layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE)))
plot.ts(y, ylab=" ", main=expression(paste('Time series plot of AR(1)-process,',
        , phi, '=', 0.9)))
acf(y, main='Autocorrelations', ylab='', ylim=c(-1, 1), ci.col='black')
pacf(y, main='Partial Autocorrelations', ylab='', ylim=c(-1, 1), ci.col='black')
dev.off()

# Ideas on AR(1)
# acf die slowly, pacf truncate
# AR(1) = infinite sum of past errors with decaying weight
# y_t = c/(1-phi) + \varepsilon_t + phi_1 \varepsilon_{t-1}
# For economic growth, if we fit AR(1), we assume that all growth is from
# technology shocks accumulation. is it true?
# Id don't think so.
# Maybe Newton or Albert Einstein are randomly generated by great nature
# but more lots of applied technology is more like learning by doing
# so economic growth model has to reflect the determinist part of human nature

###############################################################################
# MA(2)
###############################################################################
# Simulation of MA(1)-process with $\theta = 0.8$
set.seed(15689)
y <- arima.sim(n = 100, list(ma = c(-0.2, 0.65)))
pdf('./Figures/MA2Sim.pdf', width=9, height=8)
par(layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE)))
plot.ts(y, ylab=" ", main=expression(paste('Time series plot of MA(1)-process,',
        , phi[1], '=', -0.2, phi[2], '=', 0.65)))
acf(y, main='Autocorrelations', ylab='', ylim=c(-1, 1), ci.col='black')
pacf(y, main='Partial Autocorrelations', ylab='', ylim=c(-1, 1), ci.col='black')
dev.off()

# Ideas on MA()
# acf truncate, and pacf die slowly with the number of coefficients
# modeling ma means you put the data generating process in the pure random way

###############################################################################
# ARMA(2, 2)
###############################################################################
set.seed(15689)
y <- arima.sim(model=list(ar=c(.9,-.2),ma=c(-.7,.1)),n=100, innov=rnorm(100))
pdf('./Figures/ARMASim.pdf', width=9, height=8)
par(layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE)))
plot.ts(y, ylab=" ", main='Time series plot of ARMA(2, 2)-process')
acf(y, main='Autocorrelations', ylab='', ylim=c(-1, 1), ci.col='black')
pacf(y, main='Partial Autocorrelations', ylab='', ylim=c(-1, 1), ci.col='black')
dev.off()

# Ideas on ARMA()
# Similar to MA

###############################################################################
# Random Walk
###############################################################################
set.seed(96587)
e <- rnorm(500)

# pure random Walk
rw <- cumsum(e)

# trend
trend <- 1:500

# random walk with drift (long term memory)
rw.dft <- 0.5 * trend + cumsum(e)

# deterministic trend and noise (show term memeory)
determin_nosie <- e + 0.5 * trend

# Put them together
pdf('./Figures/NonStation.pdf', width=8, height=6)
par(mar=rep(5, 4))
plot.ts(determin_nosie, lty=1, ylab='', xlab='', col='#4688F1',
main='simulation and Plot for Non-stational times series', lwd=1.5)
lines(rw.dft, lty=2, col='#F34235', lwd=1.5)
par(new=T)
plot.ts(rw, lty=3, lwd=0.5, axes=FALSE, ylab="")
axis(4, pretty(range(rw)))
lines(rw, lty=3, lwd = 2, col='#4BAE4F')
legend(150, -2, legend=c('determinist+noise', 'RandomW+drift', 'RandomW'),
      col=c('#4688F1', '#F34235', '#4BAE4F'), lty=1:3)
dev.off()

# Ideas on nonstationary time series
# The GDP growth is more like random walk with drift


###############################################################################
# Unit Root with series correlation
###############################################################################
set.seed(95765)

xi <- rnorm(501, 0, 1)
rho <- 0.32
varepsilon <- c(0:500)
y_unit <- c(0:500)
y_unit[1] <- 1

for (i in 2:length(xi)){
  varepsilon[i] <- rho * varepsilon[i-1] + xi[i]
  y_unit[i] <- 0.5 + y_unit[i-1] + varepsilon[i]
}

y_random <- c(0:500)
y_random[1] <- 1

for (i in 2:length(xi)) {
  y_random[i] <- 0.5 + y_random[i-1] + xi[i]
}

omega <- 0.642
alpha <- 0.569
ep_initial <- sqrt(omega/(1-alpha))
sigma <- c(0:500)
sigma[1] <- ep_initial^2
epsilon <- c(0:500)
epsilon[1] <- ep_initial
y_arch <- c(0:500)
y_arch[1] <- 1

for (i in 2:length(xi)){
  sigma[i] <- omega + alpha * (epsilon[i-1])^2
  epsilon[i] <- sqrt(sigma[i]) * xi[i]
  y_arch[i] <- 0.5 + y_arch[i-1] + epsilon[i]
}


pdf('./Figures/UnitRootSm.pdf', width=8, height=6)
plot.ts(y_unit, col='black', lty = 1, ylab='Simulated Time Series Y',
                main='Time Series Simulation Plot', lwd=1, ylim=c(0, 250))
lines(y_random, col='red', lty = 2, lwd=1.5)
lines(y_arch, col='blue', lty = 3, lwd=2)
legend(200, 60, legend=c('Unit Root Y with series correlation',
            'Random Walk Y with drift', 'Arch Unit Root Y'),
      col=c('black', 'red', 'blue'), lty=1:3)
dev.off()

# End of Code
